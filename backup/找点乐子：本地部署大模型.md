AI 发展到现在，已然一日千里。在本地部署一个看起来还不错的大模型，能做到什么程度呢？

我有一个树莓派 4B 8G，我想看看是否能有大模型能在此落地，它的表现又将如何呢？

综合对比，希望可用且流畅，我给出了最低门槛方案：

- 模型：Qwen2.5-1.5B 或 LLaMA-3.2-1B（4bit 量化）
- 框架：Ollama（底层是 llama.cpp）
- 硬件：
  - CPU：4 核即可
  - 内存：8GB 可用，6GB 勉强
  - GPU：不需要

尽管 Qwen2.5-1.5B 或 LLaMA-3.2-1B 都还不错，但考虑母语习惯，模型选择对中文支持更好的 Qwen2.5-1.5B 。

先在我的笔记本上跑跑看看效果。

Ollama 的 1.2 GB windows 安装包也太大了，考虑自己编译二进制文件。

```bash
git clone https://github.com/ggerganov/llama.cpp
```

源码约 235MB，如果只拉取必要代码还能更小。现在需要编译出较小体积的 llama-cli.exe
手动关闭掉一些不必要的选项：

```bash
cd llama.cpp
cmake -B build ^
  -DLLAMA_CURL=OFF ^
  -DLLAMA_CUDA=OFF ^
  -DLLAMA_OPENBLAS=OFF ^
  -DLLAMA_METAL=OFF
cmake --build build --config Release
```

最后得到一个约 3MB 大小的 `build/bin/Release/llama-cli.exe`

接下来就是导入模型了，到 HuggingFace，搜索：qwen2.5-1.5b-q4_k_m.gguf
这表示：

- 模型：Qwen2.5-1.5B
- 格式：GGUF（llama.cpp 专用）
- 量化：Q4_K_M（首选，体积/效果最优）

大小约 900 MB。

将下载好的文件 qwen2.5-1.5b-instruct-q4_k_m.gguf（文件名类似，可能略有差异）放入 llama.cpp/models 下

```bash
./build/bin/Release/llama-cli.exe -m ./models/qwen2.5-1.5b-instruct-q4_k_m.gguf -c 4096 -n 256 -t 6 
```

参数说明：
- -m：模型路径
- -t：线程数（= 物理核数）
- -c：上下文长度（4k 足够）
- -n：最大生成 token

上下文 = 你的 Prompt + 模型的回复。如果 Prompt 本身很长，留给回复的空间就少了。如果总数超过 4096，模型会开始丢掉最前面的记忆，这会导致它忘记你最初的要求，从而乱写或草草收尾。而 Token 数量可以代表模型输出长文本的能力，模型最多能生成的 Token 数量越大，可以输出的文本就会更长。

进阶操作：

在 llama.cpp 中，-n（或者 --n-predict）代表的是模型最多能生成的 Token 数量。`-n 256` 意味着模型写到 256 个 Token（大约 150-200 个汉字）时，无论话有没有说完，程序都会强制停止，影响体验。

文档中告诉我们可以使用` -n -1 `（预测无限 token），来取消硬性的长度截断。

此外还可开启一些参数，来帮助我们生成长文本，如：

- -cnv (conversation)：会启动交互界面。模型输出完一段话后不会直接关闭程序，而是会出现提示符等待下一次输入。如果它写一半停了，你直接回车或输入“继续”，它就能接龙。
- --ignore-eos ：会忽略模型的停止符。开启这个参数后，模型会一直写到填满 4096 的上下文为止，除非手动按 Ctrl+C 中止。这对测试模型“极限长文本”能力非常有用，但可能会导致它在正文结束后开始胡言乱语。

还有一些实用技巧，如：

- 多行输入：如果你想粘贴很长的一段 Prompt 进去，建议加上 -mli (multiline-input) 参数，这样你可以分行输入，直到输入完按特定的结束组合键。
- 系统提示词：如果你希望它稳定扮演一个“长文作家”，可以使用 -sys "你是一个专业的长篇小说家，擅长细腻的描写，请尽可能详细地展开情节，不要草草结尾。"。

```bash
 ./build/bin/Release/llama-cli.exe -m ./models/qwen2.5-1.5b-instruct-q4_k_m.gguf -c 4096 -n -1 -t 12 -cnv --min-p 0.05 --repeat-penalty 1.1
```

<img width="410" height="357" alt="Image" src="https://github.com/user-attachments/assets/b51f5c7d-324b-4e11-8f84-349edad01216" />

enjoy it ! : )

